#!/usr/bin/env python3
"""
æ·±å…¥è°ƒè¯•agnoåº“ä¸æ™ºè°±AIçš„å…¼å®¹æ€§é—®é¢˜
"""

import os
import sys
import asyncio
import json
from pathlib import Path
from dotenv import load_dotenv

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
os.chdir(project_root)

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = project_root / ".env"
if env_path.exists():
    load_dotenv(env_path)

async def debug_agno_compatibility():
    """æ·±å…¥è°ƒè¯•agnoä¸æ™ºè°±AIçš„å…¼å®¹æ€§"""
    api_key = os.getenv("ZHIPUAI_API_KEY")
    if not api_key:
        print("âŒ ZHIPUAI_API_KEY æœªé…ç½®")
        return
    
    print(f"âœ… APIå¯†é’¥å·²é…ç½®: {api_key[:10]}...")
    
    # é¦–å…ˆï¼Œç›´æ¥æµ‹è¯•OpenAIå®¢æˆ·ç«¯
    try:
        from openai import AsyncOpenAI
        
        client = AsyncOpenAI(
            api_key=api_key,
            base_url="https://open.bigmodel.cn/api/paas/v4/"
        )
        
        print("\nğŸ§ª æµ‹è¯•1: ç›´æ¥OpenAIå®¢æˆ·ç«¯è°ƒç”¨")
        simple_system = "ä½ æ˜¯ä¸€ä¸ªè§„åˆ’åŠ©æ‰‹ã€‚"
        
        response = await client.chat.completions.create(
            model="glm-4.5",
            messages=[
                {"role": "system", "content": simple_system},
                {"role": "user", "content": "åˆ¶å®šä¸€ä¸ªç®€å•è®¡åˆ’"}
            ],
            temperature=0.7,
            max_tokens=200
        )
        print(f"âœ… ç›´æ¥è°ƒç”¨æˆåŠŸ: {response.choices[0].message.content[:50]}...")
        
    except Exception as e:
        print(f"âŒ ç›´æ¥è°ƒç”¨å¤±è´¥: {e}")
        return False
    
    # ç„¶åæµ‹è¯•agnoåº“
    try:
        print("\nğŸ§ª æµ‹è¯•2: æ£€æŸ¥agnoåº“çš„å®é™…è¡Œä¸º")
        
        # å°è¯•å¯¼å…¥agno
        try:
            from agno.models.openai import OpenAIChat
            print("âœ… æˆåŠŸå¯¼å…¥agno.models.openai.OpenAIChat")
        except ImportError as e:
            print(f"âŒ æ— æ³•å¯¼å…¥agno: {e}")
            return False
        
        # åˆ›å»ºOpenAIChatå®ä¾‹
        model = OpenAIChat(
            id="glm-4.5",
            base_url="https://open.bigmodel.cn/api/paas/v4/",
            api_key=api_key,
            temperature=0.7,
            max_tokens=200
        )
        print("âœ… æˆåŠŸåˆ›å»ºOpenAIChatå®ä¾‹")
        
        # æ£€æŸ¥å¯ç”¨æ–¹æ³•
        available_methods = [method for method in dir(model) if not method.startswith('_')]
        print(f"âœ… å¯ç”¨æ–¹æ³•: {available_methods}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰aresponseæ–¹æ³•
        if hasattr(model, 'aresponse'):
            print("âœ… æ‰¾åˆ°aresponseæ–¹æ³•")
            
            # å°è¯•è°ƒç”¨aresponse
            print("\nğŸ§ª æµ‹è¯•3: è°ƒç”¨aresponseæ–¹æ³•")
            try:
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": "ä½ å¥½"}
                ]
                print(f"å‘é€æ¶ˆæ¯: {messages}")
                
                response = await model.aresponse(messages=messages)
                print(f"âœ… aresponseæˆåŠŸ: {response}")
                
                # æ£€æŸ¥responseçš„å±æ€§
                if hasattr(response, 'content'):
                    print(f"âœ… å“åº”å†…å®¹: {response.content}")
                else:
                    print(f"âœ… å“åº”å¯¹è±¡: {response}")
                    print(f"å“åº”ç±»å‹: {type(response)}")
                    print(f"å“åº”å±æ€§: {dir(response)}")
                
            except Exception as e:
                print(f"âŒ aresponseè°ƒç”¨å¤±è´¥: {e}")
                print(f"é”™è¯¯ç±»å‹: {type(e)}")
                
                # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯
                import traceback
                traceback.print_exc()
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°aresponseæ–¹æ³•")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¼‚æ­¥æ–¹æ³•
        async_methods = [method for method in dir(model) if method.startswith('a') and callable(getattr(model, method))]
        print(f"âœ… å¼‚æ­¥æ–¹æ³•: {async_methods}")
        
        return True
        
    except Exception as e:
        print(f"âŒ agnoæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(debug_agno_compatibility())
    if success:
        print("\nğŸ‰ è°ƒè¯•å®Œæˆï¼")
    else:
        print("\nğŸ’¥ è°ƒè¯•å¤±è´¥ï¼")