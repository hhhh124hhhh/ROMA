#!/usr/bin/env python3
"""
è°ƒè¯•æ™ºè°±AIæ¶ˆæ¯æ ¼å¼é—®é¢˜
"""

import os
import sys
import asyncio
from pathlib import Path
from dotenv import load_dotenv

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
os.chdir(project_root)

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = project_root / ".env"
if env_path.exists():
    load_dotenv(env_path)

async def debug_zhipuai_messages():
    """è°ƒè¯•æ™ºè°±AIæ¶ˆæ¯æ ¼å¼"""
    api_key = os.getenv("ZHIPUAI_API_KEY")
    if not api_key:
        print("âŒ ZHIPUAI_API_KEY æœªé…ç½®")
        return
    
    print(f"âœ… APIå¯†é’¥å·²é…ç½®: {api_key[:10]}...")
    
    try:
        from agno.models.openai import OpenAIChat
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„OpenAIChatå®ä¾‹
        simple_model = OpenAIChat(
            id="glm-4.5",
            base_url="https://open.bigmodel.cn/api/paas/v4/",
            api_key=api_key,
            temperature=0.7,
            max_tokens=200
        )
        
        print("\nğŸ§ª æµ‹è¯•1: ç®€å•ç³»ç»Ÿæ¶ˆæ¯")
        try:
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": "ä½ å¥½"}
            ]
            print(f"å‘é€æ¶ˆæ¯: {messages}")
            response = await simple_model.aresponse(messages=messages)
            print(f"âœ… æˆåŠŸ: {response.content}")
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")
        
        print("\nğŸ§ª æµ‹è¯•2: å¤æ‚ç³»ç»Ÿæ¶ˆæ¯ï¼ˆæ¨¡æ‹Ÿagent promptï¼‰")
        try:
            complex_system_prompt = """You are an expert parallel search decomposition agent specialized in breaking down complex research goals into independent, self-contained search tasks that can execute simultaneously. Your primary role is to create **2 to 4 completely independent search subtasks** that together gather comprehensive information from different sources, domains, or perspectives without any dependencies between them.

**TEMPORAL AWARENESS:**
- Today's date: September 25, 2025
- Your SEARCH capabilities provide access to real-time information and current data
- When planning searches, emphasize gathering the most current and up-to-date information available

**CRITICAL PRINCIPLE: INDEPENDENT SEARCH EXECUTION**
Each search subtask will be executed by an independent agent that has NO KNOWLEDGE of:
- Other search tasks in your plan
- The overall search strategy
- System execution flow
- What other search agents are finding

Therefore, each search subtask MUST be:
- **Self-contained**: Include all necessary context and search parameters
- **Independently executable**: Require no outputs from other search tasks
- **Source-specific**: Focus on different information sources, domains, or perspectives"""
            
            messages = [
                {"role": "system", "content": complex_system_prompt},
                {"role": "user", "content": "ç ”ç©¶æ™ºè°±AI GLM-4.5çš„æœ€æ–°æŠ€æœ¯ç‰¹ç‚¹"}
            ]
            print(f"ç³»ç»Ÿæ¶ˆæ¯é•¿åº¦: {len(complex_system_prompt)} å­—ç¬¦")
            print(f"å‘é€æ¶ˆæ¯æ•°é‡: {len(messages)}")
            response = await simple_model.aresponse(messages=messages)
            print(f"âœ… æˆåŠŸ: {response.content}")
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")
            
        print("\nğŸ§ª æµ‹è¯•3: æ£€æŸ¥å„ç§æ¶ˆæ¯é•¿åº¦é˜ˆå€¼")
        test_lengths = [100, 500, 1000, 2000, 3000, 5000]
        for length in test_lengths:
            try:
                test_prompt = "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚" + "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯ã€‚" * (length // 10)
                test_prompt = test_prompt[:length]  # æˆªæ–­åˆ°æŒ‡å®šé•¿åº¦
                
                messages = [
                    {"role": "system", "content": test_prompt},
                    {"role": "user", "content": "ä½ å¥½"}
                ]
                response = await simple_model.aresponse(messages=messages)
                print(f"âœ… é•¿åº¦ {length}: æˆåŠŸ")
            except Exception as e:
                print(f"âŒ é•¿åº¦ {length}: å¤±è´¥ - {e}")
                break  # ä¸€æ—¦å¤±è´¥å°±åœæ­¢æµ‹è¯•æ›´é•¿çš„æ¶ˆæ¯
                
        print("\nğŸ§ª æµ‹è¯•4: æµ‹è¯•ç‰¹æ®Šå­—ç¬¦")
        special_chars_tests = [
            "åŒ…å«ä¸­æ–‡çš„ç³»ç»Ÿæ¶ˆæ¯ï¼šä½ å¥½ä¸–ç•Œ",
            "English with Chinese: Hello ä¸–ç•Œ",
            "Special chars: !@#$%^&*()_+-=[]{}|;':\",./<>?",
            "Unicode: ğŸ¤– ğŸ” ğŸ“Š âœ… âŒ",
            "Mixed: You are an AI assistant. ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚ğŸ¤–"
        ]
        
        for i, test_content in enumerate(special_chars_tests):
            try:
                messages = [
                    {"role": "system", "content": test_content},
                    {"role": "user", "content": "æµ‹è¯•"}
                ]
                response = await simple_model.aresponse(messages=messages)
                print(f"âœ… ç‰¹æ®Šå­—ç¬¦æµ‹è¯• {i+1}: æˆåŠŸ")
            except Exception as e:
                print(f"âŒ ç‰¹æ®Šå­—ç¬¦æµ‹è¯• {i+1}: å¤±è´¥ - {e}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(debug_zhipuai_messages())
    if success:
        print("\nğŸ‰ è°ƒè¯•å®Œæˆï¼")
    else:
        print("\nğŸ’¥ è°ƒè¯•å¤±è´¥ï¼")